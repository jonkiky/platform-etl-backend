package io.opentargets.etl.backend.drug_beta

import com.typesafe.scalalogging.LazyLogging
import io.opentargets.etl.backend.SparkHelpers.applyFunToColumn
import org.apache.spark.sql.{Column, DataFrame, SparkSession}
import org.apache.spark.sql.functions._

/**
  * Class to process ChEMBL indications for incorporation into Drug.
  *
  * Output schema:
  *
  * {
  *   efo_id : str ,
  *   efo_label : str ,
  *   efo_uri : str ,
  *   max_phase_for_indication : int ,
  *   references : [
  *     {
  *       source: str ,
  *       urls: [str1, ..., strn],
  *       ids: [str1, ..., strn]
  *     }]
  *  },
  *  thera
  *
  */
class Indication(indicationsRaw: DataFrame, efoRaw: DataFrame)(
    implicit sparkSession: SparkSession) extends LazyLogging {
  import sparkSession.implicits._

  def processIndications: DataFrame = {
    logger.info("Processing indications.")
    val efoDf = getEfoDataframe(efoRaw).transform(formatEfoIds)
    val indicationDf = processIndicationsRawData
      .join(efoDf, Seq("efo_id"), "leftouter")
    val therapeuticDf = indicationDf.transform(processTherapeuticAreas)

    indicationDf.join(therapeuticDf, Seq("id"), "left_outer")
      .withColumn("struct",
        struct($"efo_id",
          $"max_phase_for_indications",
          $"references",
          $"efo_url",
          $"efo_label"
        ))
      .groupBy("id")
      .agg(
        collect_list($"struct").as("indications"),
        collect_list($"indication_therapeutic_areas").as("indication_therapeutic_areas")
      ).withColumn("number_of_indications", size($"indications"))
  }

  private def processTherapeuticAreas(dataFrame: DataFrame): DataFrame = {
    dataFrame
      .withColumn("t_labels", explode($"therapeutic_labels"))
      .withColumn("t_codes", explode($"therapeutic_codes"))
      .groupBy("id", "t_codes", "t_labels")
      .agg(count("*").as("count"))
      .orderBy(asc("count"))
      .withColumn("struct", struct(
        $"t_codes".as("therapeutic_code"),
        $"t_labels".as("therapeutic_label"),
        $"count"
      ))
      .groupBy("id")
      .agg(
        collect_list("struct").as("indication_therapeutic_areas"))
  }

  private def processIndicationsRawData: DataFrame = {
    val df = formatEfoIds(this.indicationsRaw)

    val splitComma = split(_: Column, ",")
    // flatten hierarchy
    df.withColumn("r", explode($"indication_refs"))
      .select($"molecule_chembl_id".as("id"),
              $"efo_id",
              $"max_phase_for_ind",
              $"r.ref_id",
              $"r.ref_type",
              $"r.ref_url")
      // handle case where clinical trials packs multiple ids into a csv string
      .transform(applyFunToColumn("ref_id", _, splitComma))
      .transform(applyFunToColumn("ref_id", _, explode))
      // group reference ids and urls by ref_type
      .groupBy("id", "efo_id", "ref_type")
      .agg(max("max_phase_for_ind").as("max_phase_for_ind"),
           collect_list("ref_id").as("ids"),
           collect_list("ref_url").as("urls"))
      // nest references and find max_phase
      .withColumn("references",
                  struct(
                    $"ref_type".as("source"),
                    $"ids",
                    $"urls"
                  ))
      .groupBy("id", "efo_id")
      .agg(
        max("max_phase_for_ind").as("max_phase_for_indications"),
        collect_list("references").as("references")
      )

  }

  /**
    *
    * @param rawEfoData taken from the `disease` input data
    * @return dataframe of `efo_id`, `efo_label`, `efo_uri`, `therapeutic_codes`, `therapeutic_labels`
    */
  private def getEfoDataframe(rawEfoData: DataFrame): DataFrame = {
    val columnsOfInterest = Seq(("code", "efo_url"),
                                ("label", "efo_label"),
                                ("therapeutic_codes", "therapeutic_codes"),
                                ("therapeutic_labels", "therapeutic_labels"))
    val df = rawEfoData
      .select(columnsOfInterest.map(_._1).map(col): _*)
      .withColumn("efo_id", Indication.splitAndTakeLastElement(col("code")))
    // rename columns
    columnsOfInterest.foldLeft(df)((d, names) => d.withColumnRenamed(names._1, names._2))
  }

  /**
    *
    * @param indicationDf
    * @return dataframe with efo_ids in form EFO_xxxx instead of EFO:xxxx
    */
  private def formatEfoIds(indicationDf: DataFrame): DataFrame = {
    val idColumn = "efo_id"
    val tempColumn = "x"
    indicationDf
      .withColumnRenamed(idColumn, tempColumn)
      .withColumn(idColumn, regexp_replace(col(tempColumn), ":", "_"))
      .drop(tempColumn)
  }

}

object Indication extends Serializable with LazyLogging {

  /**
    * Split a column and return last element
    * @param x column of strings to split
    * @param pattern to use in split
    * @return last element from array generated by split.
    */
  def splitAndTakeLastElement(x: Column, pattern: String = "/"): Column = {

    val strArr: Column = split(x, pattern)
    val ind = size(strArr).minus(1)
    strArr(ind)

  }
}
